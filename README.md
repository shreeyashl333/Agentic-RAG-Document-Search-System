# ğŸ” Agentic RAG Document Search System

A **productionâ€‘style Retrievalâ€‘Augmented Generation (RAG)** application that demonstrates how modern AI teams build **documentâ€‘grounded questionâ€‘answering systems** using **LangChain, LangGraph, FAISS, and OpenAI models**.

This project is designed to be **recruiterâ€‘believable**: clean architecture, agentic orchestration, transparent sources, and an interactive UI.

---

## ğŸš€ What This Project Demonstrates

* Endâ€‘toâ€‘end **RAG pipeline** (ingestion â†’ chunking â†’ embeddings â†’ retrieval â†’ answer generation)
* **Agentic reasoning** using **LangGraph + ReAct agents**
* Support for **multiple data sources**:

  * ğŸŒ Web URLs
  * ğŸ“„ Local PDFs / text files
* **Vector search** with FAISS
* **Sourceâ€‘aware answers** (documents shown alongside responses)
* **Streamlit UI** for interactive exploration
* Clean separation of concerns (config, ingestion, vector store, graph, UI)

---

## ğŸ§  System Architecture

```
User Question
     â”‚
     â–¼
LangGraph Orchestrator
     â”‚
     â”œâ”€â”€ Retrieve Relevant Chunks (FAISS)
     â”‚
     â”œâ”€â”€ Toolâ€‘aware ReAct Agent
     â”‚       â”œâ”€â”€ Vector Retriever Tool
     â”‚       â””â”€â”€ Wikipedia Tool (fallback knowledge)
     â”‚
     â–¼
Final Answer + Source Documents
```

The **agent** decides *how* to answer using tools rather than blindly stuffing context into a prompt.

---

## ğŸ“‚ Project Structure

```
rag-document-search/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/                # LLM + system configuration
â”‚   â”œâ”€â”€ document_ingestion/    # URL / PDF ingestion + chunking
â”‚   â”œâ”€â”€ vectorstore/           # FAISS + embeddings
â”‚   â”œâ”€â”€ graph_builder/         # LangGraph orchestration
â”‚   â”œâ”€â”€ node/                  # Retrieval + ReAct agent nodes
â”‚   â””â”€â”€ state/                 # Graph state definitions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ urls.txt               # List of URLs to ingest
â”‚   â””â”€â”€ attention.pdf          # Example local document
â”œâ”€â”€ streamlit_app.py           # Interactive UI
â”œâ”€â”€ main.py                    # CLI entrypoint
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¸ Application Screenshots

> These screenshots were captured from a real run of the system.

### System Ready â€“ Documents Indexed

<img width="1912" height="947" alt="Doc Search pic1" src="https://github.com/user-attachments/assets/853ccd8b-230b-4de5-8ca5-445799666e37" />

### Asking a Question

<img width="1342" height="658" alt="doc search pic 2" src="https://github.com/user-attachments/assets/241c765e-a978-4020-b773-4a48a46ba64f" />


### Generated Answer

<img width="1778" height="869" alt="doc search pic 3" src="https://github.com/user-attachments/assets/74772adb-ec70-4e60-bfae-86739fa8ceb1" />


### Retrieved Source Documents

<img width="1641" height="919" alt="doc search pic 4" src="https://github.com/user-attachments/assets/2fe0d01e-d824-4e22-b9a4-ff6bcedfcb8a" />


### Response Timing & History

<img width="1755" height="926" alt="doc search pic 5" src="https://github.com/user-attachments/assets/3817d874-44b4-4dbd-93c9-ecaa51582cec" />


---

## âš™ï¸ How It Works (Detailed Flow)

### 1. Document Ingestion

* URLs loaded via `WebBaseLoader`
* PDFs parsed using `PyPDFLoader`
* All documents normalized into LangChain `Document` objects

### 2. Chunking Strategy

* Recursive text splitting
* Configurable `chunk_size` and `chunk_overlap`
* Designed to balance retrieval precision vs context recall

### 3. Embeddings & Vector Store

* OpenAI embeddings
* FAISS index built inâ€‘memory (optionally persistable)
* Retriever exposed as a **tool** to the agent

### 4. Agentic Reasoning (LangGraph)

* Graph nodes:

  * **Retriever Node** â€“ fetches relevant chunks
  * **Responder Node** â€“ ReAct agent decides how to answer
* Agent can:

  * Use retrieved documents
  * Fall back to Wikipedia for general knowledge

### 5. Answer Generation

* ReAct agent synthesizes a grounded answer
* Returns:

  * Final answer
  * Retrieved source documents

---

## ğŸ–¥ï¸ Running the Project Locally

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/rag-document-search.git
cd rag-document-search
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Environment Variables

Create a `.env` file:

```bash
OPENAI_API_KEY=your_api_key_here
```

> âš ï¸ Never commit `.env` to GitHub

### 5ï¸âƒ£ Run the Streamlit App

```bash
streamlit run streamlit_app.py
```

### 6ï¸âƒ£ Run via CLI (Optional)

```bash
python main.py
```

---

## ğŸ” Example Questions

* *What are transformers?*
* *What problem does selfâ€‘attention solve?*
* *Summarize the key ideas from the Attention Is All You Need paper*

---

## ğŸ§ª Design Decisions (Why This Matters)

* **Agentic RAG** instead of naive RAG â†’ closer to production systems
* **LangGraph** for explicit orchestration â†’ debuggable + extensible
* **Toolâ€‘based retrieval** â†’ scalable beyond single vector store
* **Source transparency** â†’ critical for trust and debugging

---

## ğŸ“ˆ Future Enhancements

* Persistent FAISS index
* Hybrid search (BM25 + dense)
* RAG evaluation harness (precision@k, faithfulness)
* Multiâ€‘document citations
* Authâ€‘enabled deployment

---

## ğŸ§‘â€ğŸ’» Who This Project Is For

* Recruiters evaluating **Applied AI / ML / LLM Engineers**
* Engineers looking for a **clean RAG reference implementation**
* Teams exploring **agentâ€‘based LLM systems**

---

## ğŸ“œ License

MIT License

---

**If youâ€™re a recruiter:** this project mirrors how modern AI teams build retrievalâ€‘augmented systems in production environments, with attention to correctness, modularity, and explainability.
